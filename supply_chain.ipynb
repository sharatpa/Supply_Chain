{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supply_chain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZR2ul4X8d1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fb43d22-d7a0-4cf5-e2c2-272ca7f5cb37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huqnzkuk9W6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Copy contents from My Drive to \"/content\" in order to import all scripts.\n",
        "!cp -r /content/drive/My\\ Drive/SC_RL /content"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3f9ENl3fo_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rm -rf SC_RL/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aS4omrnVaU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "1e77c91d-3a4e-41b9-f176-998931b8003c"
      },
      "source": [
        "!pip install import_ipynb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=6e5fc51fb74fdc26d3298863b88f09237fc0941e7d91be45687756da9b3d6e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiXti2R48Owo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1fba482-d9e5-4aa2-978f-2fe7b1da1980"
      },
      "source": [
        "## Import libraries.\n",
        "import import_ipynb\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from SC_RL.Environments import warehouse_store"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/SC_RL/Environments/warehouse_store.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxOGD9neYH4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata_file = Path(os.getcwd()+\"/SC_RL/data/instacart-market-basket-analysis/products_metadata.xlsx\")\n",
        "forecast_data = Path(os.getcwd()+\"/SC_RL/data/instacart-market-basket-analysis/scenarios.xlsx\")\n",
        "w = warehouse_store.warehouse_store()\n",
        "num_products = 10\n",
        "min_produts = 0\n",
        "max_products = 20 ## Double check."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUrwAiiP9Log",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reward_function(states, actions):\n",
        "  '''\n",
        "  Should ensure that inventory is stocked, but at the same time, ensure that\n",
        "  wastage is minimized.\n",
        "  1 - (quantity_restocked/total quantity of products)\n",
        "    - (quantity of expired products/total quantity of products)\n",
        "  '''\n",
        "  ## only check quantity portion when it is thrown away.\n",
        "  p_restocked = np.ndarray.sum(actions)\n",
        "  q_max = np.ndarray.sum(states[0:num_products,0])\n",
        "  reward = 1 - (p_restocked+states[num_products+1,0])/q_max\n",
        "  return reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLQBpXskMAb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6cf6f750-46b6-4d91-b83a-4b147d74fbc0"
      },
      "source": [
        "## Test passing a function as argument here:\n",
        "# total_reward = w.simulate(metadata_file,forecast_data,reward_function) # Need not initialize; just simulate.\n",
        "# print(total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_aHTI5ZCCVz",
        "colab_type": "text"
      },
      "source": [
        "## **Actor-Critic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-vbrBY5jCbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Parameters:\n",
        "episodes = 100\n",
        "gamma = 0.9           # reward discount in TD error\n",
        "lr_actor = 5e-6       # learning rate for actor\n",
        "lr_critic = 5e-3      # learning rate for critic"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDP-d7g5Krv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.d1 = tf.keras.layers.Dense(40,activation='relu')\n",
        "    self.d2 = tf.keras.layers.Dense(20,activation='relu')\n",
        "    self.v = tf.keras.layers.Dense(1, activation = None)\n",
        "\n",
        "  def call(self, input_data):\n",
        "    x = self.d1(input_data)\n",
        "    x = self.d2(x)\n",
        "    v = self.v(x)\n",
        "    return v\n",
        "    \n",
        "\n",
        "class Actor(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.d1 = tf.keras.layers.Dense(40,activation='relu')\n",
        "    self.d2 = tf.keras.layers.Dense(20,activation='relu')\n",
        "    self.a = tf.keras.layers.Dense(num_products,activation='relu')\n",
        "\n",
        "  def call(self, input_data):\n",
        "    x = self.d1(input_data)\n",
        "    x = self.d2(x)\n",
        "    a = self.a(x)\n",
        "    return a"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSLO_Gg-bme6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, gamma = 0.99):\n",
        "    self.gamma = gamma\n",
        "    self.a_opt = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
        "    self.c_opt = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
        "    self.actor = Actor()\n",
        "    self.critic = Critic()\n",
        "    \n",
        "  def act(self,state):\n",
        "    prob = self.actor(np.array([state]))\n",
        "    #print(prob)\n",
        "    prob = prob.numpy()\n",
        "    # dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
        "    dist = tfp.distributions.Normal(loc=0, scale=1)\n",
        "    action = dist.sample()\n",
        "    return int(action.numpy()[0])\n",
        "\n",
        "  def actor_loss(self, prob, action, td):\n",
        "    dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
        "    log_prob = dist.log_prob(action)\n",
        "    loss = -log_prob*td\n",
        "    return loss\n",
        "\n",
        "  def learn(self, state, action, reward, next_state, done):\n",
        "    state = np.array([state])\n",
        "    next_state = np.array([next_state])\n",
        "    with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "      p = self.actor(state, training=True)\n",
        "      v =  self.critic(state,training=True)\n",
        "      vn = self.critic(next_state, training=True)\n",
        "      td = reward + self.gamma*vn*(1-int(done)) - v\n",
        "      a_loss = self.actor_loss(p, action, td)\n",
        "      c_loss = td**2\n",
        "    grads1 = tape1.gradient(a_loss, self.actor.trainable_variables)\n",
        "    grads2 = tape2.gradient(c_loss, self.critic.trainable_variables)\n",
        "    self.a_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n",
        "    self.c_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n",
        "    return a_loss, c_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W9Bgy_0bdm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Normalize state-space:\n",
        "state_space_samples = np.array(\n",
        "    [env.observation_space.sample() for x in range(10000)])\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "scaler.fit(state_space_samples)\n",
        "\n",
        "#function to normalize states\n",
        "def scale_state(state):                 #requires input shape=(2,)\n",
        "    scaled = scaler.transform([state])\n",
        "    return scaled                       #returns shape =(1,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sblFqRVCHx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "5935c011-fb70-46d1-b1fc-ad05024c2aa3"
      },
      "source": [
        "## Training:\n",
        "scrl = Agent()\n",
        "tot_reward_vs_episode = []\n",
        "for ep in range(episodes):\n",
        "  total_reward_per_episode = 0\n",
        "  states = w.reset(metadata_file, forecast_data)\n",
        "  ## get_demand() returns a pre-determined demand of each product for timestep.\n",
        "  demand = w.get_demand()\n",
        "  all_aloss = []\n",
        "  all_closss = []\n",
        "  while current_timestep <= w.simulation_duration:\n",
        "    ## Sample action according to current policy\n",
        "    action  = np.random.randint(0,5,(num_prod,1))# action = scrl.act(states)\n",
        "    ## Execute action and observe reward & next state from E\n",
        "    next_state, reward, done = w.step(np.squeeze(action, axis=0),demand,current_timestep)\n",
        "    aloss, closs = scrl.learn(states, action, reward, next_state, done)\n",
        "    all_aloss.append(aloss)\n",
        "    all_closs.append(closs)\n",
        "    current_timestep += 1\n",
        "    total_reward_per_episode += reward\n",
        "    next_state = states\n",
        "\n",
        "  tot_reward_vs_episode.append(total_reward_per_episode)\n",
        "  '''Plot reward here.'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c463d79fc488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m## get_demand() returns a pre-determined demand of each product for timestep.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mdemand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_demand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mall_aloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mall_closss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SC_RL/Environments/warehouse_store.ipynb\u001b[0m in \u001b[0;36mget_demand\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4urg-I_iXhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}